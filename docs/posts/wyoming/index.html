<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>ü¶¨ Wyoming In Go | üîÆ Merlin's Beard</title>
<meta name=keywords content><meta name=description content="The Setup I was working on a side project the other day and I needed to generate some spoken audio from generated text. This is called &ldquo;Text to Speech&rdquo; or &ldquo;TTS&rdquo;. There&rsquo;s also &ldquo;Speech to Text&rdquo; or STT, and a few other acronyms to memorize for fun.
I&rsquo;m a huge fan of Home Assistant and last year they had several updates for their &ldquo;Year of the Voice&rdquo;. These updates gave the project functionality like those home smart speakers that were super popular for a while."><meta name=author content><link rel=canonical href=https://john-pettigrew.github.io/posts/wyoming/><link crossorigin=anonymous href=/assets/css/stylesheet.fc220c15db4aef0318bbf30adc45d33d4d7c88deff3238b23eb255afdc472ca6.css integrity="sha256-/CIMFdtK7wMYu/MK3EXTPU18iN7/MjiyPrJVr9xHLKY=" rel="preload stylesheet" as=style><link rel=icon href=https://john-pettigrew.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://john-pettigrew.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://john-pettigrew.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://john-pettigrew.github.io/apple-touch-icon.png><link rel=mask-icon href=https://john-pettigrew.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://john-pettigrew.github.io/posts/wyoming/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="ü¶¨ Wyoming In Go"><meta property="og:description" content="The Setup I was working on a side project the other day and I needed to generate some spoken audio from generated text. This is called &ldquo;Text to Speech&rdquo; or &ldquo;TTS&rdquo;. There&rsquo;s also &ldquo;Speech to Text&rdquo; or STT, and a few other acronyms to memorize for fun.
I&rsquo;m a huge fan of Home Assistant and last year they had several updates for their &ldquo;Year of the Voice&rdquo;. These updates gave the project functionality like those home smart speakers that were super popular for a while."><meta property="og:type" content="article"><meta property="og:url" content="https://john-pettigrew.github.io/posts/wyoming/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-11-08T13:20:23-06:00"><meta property="article:modified_time" content="2024-11-08T13:20:23-06:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="ü¶¨ Wyoming In Go"><meta name=twitter:description content="The Setup I was working on a side project the other day and I needed to generate some spoken audio from generated text. This is called &ldquo;Text to Speech&rdquo; or &ldquo;TTS&rdquo;. There&rsquo;s also &ldquo;Speech to Text&rdquo; or STT, and a few other acronyms to memorize for fun.
I&rsquo;m a huge fan of Home Assistant and last year they had several updates for their &ldquo;Year of the Voice&rdquo;. These updates gave the project functionality like those home smart speakers that were super popular for a while."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://john-pettigrew.github.io/posts/"},{"@type":"ListItem","position":2,"name":"ü¶¨ Wyoming In Go","item":"https://john-pettigrew.github.io/posts/wyoming/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"ü¶¨ Wyoming In Go","name":"ü¶¨ Wyoming In Go","description":"The Setup I was working on a side project the other day and I needed to generate some spoken audio from generated text. This is called \u0026ldquo;Text to Speech\u0026rdquo; or \u0026ldquo;TTS\u0026rdquo;. There\u0026rsquo;s also \u0026ldquo;Speech to Text\u0026rdquo; or STT, and a few other acronyms to memorize for fun.\nI\u0026rsquo;m a huge fan of Home Assistant and last year they had several updates for their \u0026ldquo;Year of the Voice\u0026rdquo;. These updates gave the project functionality like those home smart speakers that were super popular for a while.","keywords":[],"articleBody":"The Setup I was working on a side project the other day and I needed to generate some spoken audio from generated text. This is called ‚ÄúText to Speech‚Äù or ‚ÄúTTS‚Äù. There‚Äôs also ‚ÄúSpeech to Text‚Äù or STT, and a few other acronyms to memorize for fun.\nI‚Äôm a huge fan of Home Assistant and last year they had several updates for their ‚ÄúYear of the Voice‚Äù. These updates gave the project functionality like those home smart speakers that were super popular for a while. One benefit of having this in Home Assistant is privacy! All your requests to ‚Äúturn off the kitchen light‚Äù will be safely stored away from prying eyes, on a server you trust.\nThese updates connect Home Assistant to servers running the Wyoming Protocol (More details below). I say servers (plural) because the different pieces (TTS, STT, etc.) run separately. Which is great so you aren‚Äôt having to run a bunch of AI models that you don‚Äôt really need. The TTS server I‚Äôm using is called Piper. The only problem is that since these servers use that Wyoming protocol and aren‚Äôt normal web servers, you can‚Äôt just use normal HTTP to request data.\nOne Problem - Several Solutions For my project, I want a simple command where I can have text as an input and output an audio file. One solution here would be to just write a python script to run the Piper AI model locally instead. This would work, but I would be potentially loading the same models into memory multiple times. Plus, I‚Äôve been enjoying writing more code with Go lately. Another great thing about connecting to a remote server instead is that I can just use my running Piper instance that Home Assistant is using for any future projects. Plus, I‚Äôll also have a small library in Go for talking over Wyoming that I can use later. So, I decided to create wyoming-cli!\nWyoming (The Protocol) Overall, the Wyoming protocol is pretty simple. After you connect over TCP, data is structured like jsonl. Which means JSON with newline characters after each message. But, Wyoming can also send PCM audio data.\nThe data being sent is structured like this: first a ‚Äúmessage‚Äù json string is sent followed by a newline character. Then, an optional ‚Äúdata‚Äù json string and an optional ‚Äúpayload‚Äù that usually contains PCM audio, is sent. Then the pattern repeats if there are multiple messages.\nSo it ends up looking kind of like this:\n{json message}\\n {optional data}[optional payload]{json message}\\n ... {optional data}[optional payload]{json message}\\n Reading and parsing the initial message is easy since you just need to read from the TCP connection until that '\\n' newline character is seen.\nHere‚Äôs an example of what that message might look like:\n{ \"type\": \"synthesize\", \"data\": { \"text\": \"Hello World\" } } The ‚Äútype‚Äù field describes what type of message is actually being sent. It can either be a request or a response message. ‚Äúsynthesize‚Äù is a request for piper to start generating audio.\nThe message also has a ‚Äúdata_length‚Äù and a ‚Äúpayload_length‚Äù field which are the number of bytes that are to follow for each. Here is an example of what the message sent for some audio data might look like:\n{ \"type\": \"audio-chunk\", \"data_length\": 42, \"payload_length\": 1024, \"data\": { \"rate\": 22050, \"width\": 2, \"channels\": 1 } } The ‚Äúdata‚Äù field in this example contains metadata about the audio like the audio rate, width, and number of channels. This is important since it actually describes how to play the audio. This is also needed if you want to later convert that PCM audio into something more typical like ‚Äúwav‚Äù or ‚Äúmp3‚Äù. However, this ‚Äúdata‚Äù field is not the same as the ‚Äúdata‚Äù referenced by ‚Äúdata_length‚Äù and sent after the message. So be careful to not mix those up like I did.\nFinally, the optional payload is sent. If you are generating audio with Piper, this is the actual PCM audio. Audio being sent will start with an ‚Äúaudio-start‚Äù message type to signal some audio is going to be sent. Then multiple ‚Äúaudio-chunk‚Äù messages are sent with the actual audio. Finally, an ‚Äúaudio-stop‚Äù message is sent to signal that all of the audio was sent.\n[audio-start] [audio-chunk] ... [audio-chunk] [audio-stop] Outputs To more closely match the existing Piper options, wyoming-cli can output to a WAV file with ‚Äú‚Äìoutput_file‚Äù or output the raw PCM audio to be played immediately using something like ‚Äúaplay‚Äù with the ‚Äú‚Äìoutput-raw‚Äù option.\nConverting Audio I had a lot of this blog post written and the code done when something started to bug me. The Wyoming server will send the actual audio data as PCM audio. This makes it easy to immediately start playing. But, if you want to save the file for later, then you‚Äôll likely want to convert it to a more common audio format (like WAV). When I initially wrote the code for this project, I used ‚Äúffmpeg‚Äù to convert the audio:\n... // convert cmd := exec.Command( \"ffmpeg\", \"-f\", \"s16le\", \"-ar\", strconv.Itoa(rate), \"-ac\", strconv.Itoa(channels), \"-i\", PCMFilePath, outputWavFilePath, ) ... Now, this is fine. But one of the cool parts about writing in Go is that I can compile a project and just need the compiled binary to actually run it. Unfortunately here, I would also need to make sure that ‚Äúffmpeg‚Äù is on the system too. It turns out, converting PCM audio to a WAV file is actually pretty simple. You can think of a WAV file as a container for data. To create one, you just need to write a header describing the data and then you can append all of the PCM audio after that.\nWAVHeaderFields := []any{ // RIFF []byte(\"RIFF\"), // Chunk ID int32(36 + PCMFileStat.Size()), // Chunk Size []byte(\"WAVE\"), // Format // fmt []byte(\"fmt \"), // Subchunk1 ID int32(16), // Subchunk1 Size int16(1), // AudioFormat (PCM) int16(channels), // Num Channels int32(rate), // Sample Rate int32(byteRate), // Byte Rate int16(blockAlign), // Block Align int16(bitsPerSample), // Bits Per Sample // data []byte(\"data\"), // Subchunk2 ID int32(PCMFileStat.Size()), // Subchunk2 Size } for _, field := range WAVHeaderFields { err = binary.Write(outputFile, binary.LittleEndian, field) if err != nil { return err } } The header is broken up into 3 sections here. The ‚ÄúRIFF‚Äù section is the main header section and contains the size of the full header + audio data (minus 8 bytes for the ‚ÄúChunk ID‚Äù and ‚ÄúChunk Size‚Äù). Following that, there is a ‚Äúfmt \" section that describes how to play the audio and a ‚Äúdata‚Äù section that contains the length of the data that follows.\nResults Now I can just run this command to generate audio for my project:\nwyoming-cli tts -addr 'my_piper_server:10200' -text 'Hello world' --output_file './hello.wav' or run this to stream the audio directly to my speakers:\nwyoming-cli tts -addr 'my_piper_server:10200' -text 'Hello world' --output-raw | aplay -r 22050 -f S16_LE -t raw - Without needing to run another instance of Piper. Mission accomplished!\nThis was definitely a fun project, and I‚Äôm planning to build functionality for talking with other Wyoming services like ‚ÄúSTT‚Äù. Feel free to try out wyoming-cli on my Github. Definitely expect some bugs and if you see any please open an issue!\nUntil Next time!\n","wordCount":"1199","inLanguage":"en","datePublished":"2024-11-08T13:20:23-06:00","dateModified":"2024-11-08T13:20:23-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://john-pettigrew.github.io/posts/wyoming/"},"publisher":{"@type":"Organization","name":"üîÆ Merlin's Beard","logo":{"@type":"ImageObject","url":"https://john-pettigrew.github.io/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://john-pettigrew.github.io/ accesskey=h title="üîÆ Merlin's Beard (Alt + H)">üîÆ Merlin's Beard</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">ü¶¨ Wyoming In Go</h1><div class=post-meta><span title='2024-11-08 13:20:23 -0600 CST'>November 8, 2024</span></div></header><div class=post-content><h2 id=the-setup>The Setup<a hidden class=anchor aria-hidden=true href=#the-setup>#</a></h2><p>I was working on a side project the other day and I needed to generate some spoken audio from generated text. This is called &ldquo;Text to Speech&rdquo; or &ldquo;TTS&rdquo;. There&rsquo;s also &ldquo;Speech to Text&rdquo; or STT, and a few other acronyms to memorize for fun.</p><p>I&rsquo;m a huge fan of Home Assistant and last year they had several updates for their &ldquo;Year of the Voice&rdquo;. These updates gave the project functionality like those home smart speakers that were super popular for a while. One benefit of having this in Home Assistant is privacy! All your requests to &ldquo;turn off the kitchen light&rdquo; will be safely stored away from prying eyes, on a server you trust.</p><p>These updates connect Home Assistant to servers running the <a href=https://github.com/rhasspy/wyoming><em>Wyoming Protocol</em></a> (More details below). I say servers (plural) because the different pieces (TTS, STT, etc.) run separately. Which is great so you aren&rsquo;t having to run a bunch of AI models that you don&rsquo;t really need. The TTS server I&rsquo;m using is called <a href=https://github.com/rhasspy/wyoming-piper>Piper</a>. The only problem is that since these servers use that Wyoming protocol and aren&rsquo;t normal web servers, you can&rsquo;t just use normal HTTP to request data.</p><h2 id=one-problem---several-solutions>One Problem - Several Solutions<a hidden class=anchor aria-hidden=true href=#one-problem---several-solutions>#</a></h2><p>For my project, I want a simple command where I can have text as an input and output an audio file. One solution here would be to just write a python script to run the Piper AI model locally instead. This would work, but I would be potentially loading the same models into memory multiple times. Plus, I&rsquo;ve been enjoying writing more code with Go lately. Another great thing about connecting to a remote server instead is that I can just use my running Piper instance that Home Assistant is using for any future projects. Plus, I&rsquo;ll also have a small library in Go for talking over Wyoming that I can use later. So, I decided to create <a href=https://github.com/john-pettigrew/wyoming-cli>wyoming-cli</a>!</p><h2 id=wyoming-the-protocol>Wyoming (The Protocol)<a hidden class=anchor aria-hidden=true href=#wyoming-the-protocol>#</a></h2><p>Overall, the Wyoming protocol is pretty simple. After you connect over TCP, data is structured like <a href=https://jsonlines.org/>jsonl</a>. Which means JSON with newline characters after each message. But, Wyoming can also send PCM audio data.</p><p>The data being sent is structured like this: first a &ldquo;message&rdquo; json string is sent followed by a newline character. Then, an optional &ldquo;data&rdquo; json string and an optional &ldquo;payload&rdquo; that usually contains PCM audio, is sent. Then the pattern repeats if there are multiple messages.</p><p>So it ends up looking kind of like this:</p><pre tabindex=0><code>{json message}\n
{optional data}[optional payload]{json message}\n
...
{optional data}[optional payload]{json message}\n
</code></pre><p>Reading and parsing the initial message is easy since you just need to read from the TCP connection until that <code>'\n'</code> newline character is seen.</p><p>Here&rsquo;s an example of what that message might look like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;synthesize&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;data&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;text&#34;</span>: <span style=color:#e6db74>&#34;Hello World&#34;</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The &ldquo;type&rdquo; field describes what type of message is actually being sent. It can either be a request or a response message. &ldquo;synthesize&rdquo; is a request for piper to start generating audio.</p><p>The message also has a &ldquo;data_length&rdquo; and a &ldquo;payload_length&rdquo; field which are the number of bytes that are to follow for each. Here is an example of what the message sent for some audio data might look like:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;type&#34;</span>: <span style=color:#e6db74>&#34;audio-chunk&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;data_length&#34;</span>: <span style=color:#ae81ff>42</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;payload_length&#34;</span>: <span style=color:#ae81ff>1024</span>,
</span></span><span style=display:flex><span>    <span style=color:#f92672>&#34;data&#34;</span>: {
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;rate&#34;</span>: <span style=color:#ae81ff>22050</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;width&#34;</span>: <span style=color:#ae81ff>2</span>,
</span></span><span style=display:flex><span>        <span style=color:#f92672>&#34;channels&#34;</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The &ldquo;data&rdquo; field in this example contains metadata about the audio like the audio rate, width, and number of channels. This is important since it actually describes <em>how</em> to play the audio. This is also needed if you want to later convert that PCM audio into something more typical like &ldquo;wav&rdquo; or &ldquo;mp3&rdquo;. However, this &ldquo;data&rdquo; field is not the same as the &ldquo;data&rdquo; referenced by &ldquo;data_length&rdquo; and sent after the message. So be careful to not mix those up like I did.</p><p>Finally, the optional payload is sent. If you are generating audio with Piper, this is the actual PCM audio.
Audio being sent will start with an &ldquo;audio-start&rdquo; message type to signal some audio is going to be sent. Then multiple &ldquo;audio-chunk&rdquo; messages are sent with the actual audio. Finally, an &ldquo;audio-stop&rdquo; message is sent to signal that all of the audio was sent.</p><pre tabindex=0><code>[audio-start]
[audio-chunk]
...
[audio-chunk]
[audio-stop]
</code></pre><h2 id=outputs>Outputs<a hidden class=anchor aria-hidden=true href=#outputs>#</a></h2><p>To more closely match the existing <a href=https://github.com/rhasspy/piper>Piper</a> options, wyoming-cli can output to a WAV file with &ldquo;&ndash;output_file&rdquo; or output the raw PCM audio to be played immediately using something like &ldquo;aplay&rdquo; with the &ldquo;&ndash;output-raw&rdquo; option.</p><h2 id=converting-audio>Converting Audio<a hidden class=anchor aria-hidden=true href=#converting-audio>#</a></h2><p>I had a lot of this blog post written and the code done when something started to bug me. The Wyoming server will send the actual audio data as PCM audio. This makes it easy to immediately start playing. But, if you want to save the file for later, then you&rsquo;ll likely want to convert it to a more common audio format (like WAV). When I initially wrote the code for this project, I used &ldquo;ffmpeg&rdquo; to convert the audio:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#f92672>...</span>
</span></span><span style=display:flex><span><span style=color:#75715e>// convert
</span></span></span><span style=display:flex><span><span style=color:#75715e></span><span style=color:#a6e22e>cmd</span> <span style=color:#f92672>:=</span> <span style=color:#a6e22e>exec</span>.<span style=color:#a6e22e>Command</span>(
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;ffmpeg&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;-f&#34;</span>, <span style=color:#e6db74>&#34;s16le&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;-ar&#34;</span>, <span style=color:#a6e22e>strconv</span>.<span style=color:#a6e22e>Itoa</span>(<span style=color:#a6e22e>rate</span>),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;-ac&#34;</span>, <span style=color:#a6e22e>strconv</span>.<span style=color:#a6e22e>Itoa</span>(<span style=color:#a6e22e>channels</span>),
</span></span><span style=display:flex><span>    <span style=color:#e6db74>&#34;-i&#34;</span>, <span style=color:#a6e22e>PCMFilePath</span>,
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>outputWavFilePath</span>,
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span><span style=color:#f92672>...</span>
</span></span><span style=display:flex><span>    
</span></span></code></pre></div><p>Now, this is <em>fine</em>. But one of the cool parts about writing in Go is that I can compile a project and just need the compiled binary to actually run it. Unfortunately here, I would also need to make sure that &ldquo;ffmpeg&rdquo; is on the system too.
It turns out, converting PCM audio to a WAV file is actually pretty simple. You can think of a WAV file as a container for data. To create one, you just need to write a header describing the data and then you can append all of the PCM audio after that.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#a6e22e>WAVHeaderFields</span> <span style=color:#f92672>:=</span> []<span style=color:#a6e22e>any</span>{
</span></span><span style=display:flex><span>    <span style=color:#75715e>// RIFF
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    []byte(<span style=color:#e6db74>&#34;RIFF&#34;</span>),                 <span style=color:#75715e>// Chunk ID
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int32(<span style=color:#ae81ff>36</span> <span style=color:#f92672>+</span> <span style=color:#a6e22e>PCMFileStat</span>.<span style=color:#a6e22e>Size</span>()), <span style=color:#75715e>// Chunk Size
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    []byte(<span style=color:#e6db74>&#34;WAVE&#34;</span>),                 <span style=color:#75715e>// Format
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// fmt
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    []byte(<span style=color:#e6db74>&#34;fmt &#34;</span>),       <span style=color:#75715e>// Subchunk1 ID
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int32(<span style=color:#ae81ff>16</span>),            <span style=color:#75715e>// Subchunk1 Size
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int16(<span style=color:#ae81ff>1</span>),             <span style=color:#75715e>// AudioFormat (PCM)
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int16(<span style=color:#a6e22e>channels</span>),      <span style=color:#75715e>// Num Channels
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int32(<span style=color:#a6e22e>rate</span>),          <span style=color:#75715e>// Sample Rate
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int32(<span style=color:#a6e22e>byteRate</span>),      <span style=color:#75715e>// Byte Rate
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int16(<span style=color:#a6e22e>blockAlign</span>),    <span style=color:#75715e>// Block Align
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int16(<span style=color:#a6e22e>bitsPerSample</span>), <span style=color:#75715e>// Bits Per Sample
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>
</span></span><span style=display:flex><span>    <span style=color:#75715e>// data
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    []byte(<span style=color:#e6db74>&#34;data&#34;</span>),            <span style=color:#75715e>// Subchunk2 ID
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>    int32(<span style=color:#a6e22e>PCMFileStat</span>.<span style=color:#a6e22e>Size</span>()), <span style=color:#75715e>// Subchunk2 Size
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> <span style=color:#a6e22e>_</span>, <span style=color:#a6e22e>field</span> <span style=color:#f92672>:=</span> <span style=color:#66d9ef>range</span> <span style=color:#a6e22e>WAVHeaderFields</span> {
</span></span><span style=display:flex><span>    <span style=color:#a6e22e>err</span> = <span style=color:#a6e22e>binary</span>.<span style=color:#a6e22e>Write</span>(<span style=color:#a6e22e>outputFile</span>, <span style=color:#a6e22e>binary</span>.<span style=color:#a6e22e>LittleEndian</span>, <span style=color:#a6e22e>field</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#a6e22e>err</span> <span style=color:#f92672>!=</span> <span style=color:#66d9ef>nil</span> {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> <span style=color:#a6e22e>err</span>
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>The header is broken up into 3 sections here. The &ldquo;RIFF&rdquo; section is the main header section and contains the size of the full header + audio data (minus 8 bytes for the &ldquo;Chunk ID&rdquo; and &ldquo;Chunk Size&rdquo;). Following that, there is a &ldquo;fmt " section that describes how to play the audio and a &ldquo;data&rdquo; section that contains the length of the data that follows.</p><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><p>Now I can just run this command to generate audio for my project:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>    wyoming-cli tts -addr <span style=color:#e6db74>&#39;my_piper_server:10200&#39;</span> -text <span style=color:#e6db74>&#39;Hello world&#39;</span> --output_file <span style=color:#e6db74>&#39;./hello.wav&#39;</span>
</span></span></code></pre></div><p>or run this to stream the audio directly to my speakers:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-shell data-lang=shell><span style=display:flex><span>    wyoming-cli tts -addr <span style=color:#e6db74>&#39;my_piper_server:10200&#39;</span> -text <span style=color:#e6db74>&#39;Hello world&#39;</span> --output-raw | aplay -r <span style=color:#ae81ff>22050</span> -f S16_LE -t raw -
</span></span></code></pre></div><p>Without needing to run another instance of Piper. Mission accomplished!</p><p>This was definitely a fun project, and I&rsquo;m planning to build functionality for talking with other Wyoming services like &ldquo;STT&rdquo;. Feel free to try out <a href=https://github.com/john-pettigrew/wyoming-cli>wyoming-cli</a> on my Github. Definitely expect some bugs and if you see any please open an issue!</p><p>Until Next time!</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://john-pettigrew.github.io/>üîÆ Merlin's Beard</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>